<project_plan>

  <introduction>
    <title>Introduction to Liminal Type Chat</title>
    <content>
      Liminal Type Chat is an open-source, local-first GenAI chat application designed for individuals and small teams who want to leverage their own API keys to interact with various language models (LLMs). It prioritizes excellent design principles, easy setup, and fast execution at small scales, while maintaining the flexibility to grow. Unlike managed chat services, Liminal Type Chat emphasizes:

      1. **BYOK (Bring Your Own Key)**: Complete freedom to use your own API keys with models from OpenAI, Anthropic, Google, and any other providers
      2. **Local-First Design**: Run the entire application locally, keeping your conversations private and under your control
      3. **Simple Deployment**: Minimal setup required - just Node.js and a web browser
      4. **Optimized for Small Scale**: Lean, performant implementation for individuals and small teams
      5. **Advanced LLM Orchestration** (future): Send prompts to multiple LLMs simultaneously, chain LLMs together where one model's output becomes another's input
      6. **Extensibility Framework**: Pre and post LLM hooks, plugin system, and MCP (Model Control Protocol) tooling support

      The application consists of a Node.js/Express backend and a React TypeScript frontend. The backend serves both the API and the static frontend files, eliminating CORS issues and simplifying deployment. While the system can scale to moderately larger deployments, its primary purpose is to provide a flexible, powerful chat experience for power users who value control, privacy, and extensibility.
    </content>
  </introduction>

  <terminology>
    <title>Key Terminology</title>
    <content>
      - **Domain Tier**: The core business logic layer that defines canonical data models and operations. It's agnostic to HTTP, UI concerns, or specific database implementations.
      
      - **Edge/XPI Tier**: The Experience API layer that handles HTTP requests, transforms data between UI-friendly formats and domain models, and routes to appropriate domain services. XPI stands for eXperience/Proxy/Integration.
      
      - **Canonical Models**: The definitive representation of entities within the domain tier (e.g., a ContextThread with its messages).
      
      - **DTO (Data Transfer Object)**: Objects structured for external communication, typically more simplified or specialized than canonical models.
      
      - **Domain Client Adapter**: A component that enables edge routes to communicate with domain services, either directly (in-process) or via HTTP calls (cross-process).
      
      - **Provider Pattern**: An approach where core functionality depends on abstractions rather than concrete implementations, allowing different implementations (e.g., SQLite vs PostgreSQL) to be swapped without changing business logic.
    </content>
  </terminology>

  <design_principles>
    <title>Design Principles and Objectives</title>
    <content>
      The architecture of Liminal Type Chat follows these core principles:

      1. **Separation of Concerns**
         - Domain logic is isolated from UI and API concerns
         - Data access is abstracted from business logic
         - Service responsibilities are clearly defined and focused

      2. **Flexibility in Deployment**
         - Application can run as a single process for simplicity
         - Components are designed to be distributable across processes if needed
         - Process boundaries do not dictate code organization
         - Optimized for speed and efficiency at small scales

      3. **Progressive Enhancement**
         - Start simple with SQLite for local persistence
         - Design allows for future migration to more robust databases
         - Document storage can evolve from local files to cloud storage

      4. **Developer Experience**
         - Clear patterns make the system easier to understand and extend
         - Consistent naming conventions across the codebase
         - Testability is built into the architecture
         - Easy setup with minimal configuration

      5. **User Privacy and Control**
         - Local-first approach keeps data under user control
         - Comprehensive BYOK (Bring-Your-Own-Key) model for all LLM services
         - Transparency in how data is stored and accessed
         - User owns all their data and conversation history

      6. **Advanced LLM Orchestration**
         - Architecture supports routing one prompt to multiple LLMs
         - Enables chaining LLM outputs as inputs to other LLMs
         - Pre and post-processing hooks for LLM interactions
         - Support for Model Control Protocol (MCP) tooling and function calling

      7. **Plugin Architecture**
         - Extensible design with well-defined extension points
         - Ability to add new LLM providers without changing core code
         - Support for custom pre/post processing hooks
         - Framework for custom tools and capabilities

      8. **Open Source Readiness**
         - Well-documented code and architecture
         - Clean separation of concerns to encourage contribution
         - Modular design allows for extensibility

      9. **Testing as a First-Class Concern**
         - Services designed for testability via dependency injection
         - Clear interfaces between components enable effective mocking
         - High test coverage requirements for critical paths
    </content>
  </design_principles>

  <code_examples>
    <title>Key Code Patterns</title>
    <content>
      **1. Domain Service Example:**
      ```typescript
      // src/services/core/health-service.ts
      import { DatabaseProvider } from '../../providers/db/database-provider';

      export class HealthService {
        constructor(private dbProvider: DatabaseProvider) {}
        
        async getSystemStatus(): Promise<{ status: string; timestamp: string }> {
          return {
            status: 'ok',
            timestamp: new Date().toISOString()
          };
        }
        
        async checkDbConnection(): Promise<{ status: string; checked_at: string } | null> {
          try {
            const result = await this.dbProvider.query(
              'SELECT status, checked_at FROM health_check_table ORDER BY id DESC LIMIT 1'
            );
            return result ? result : null;
          } catch (error) {
            console.error('Database health check failed:', error);
            return null;
          }
        }
      }
      ```

      **2. Domain Route Example:**
      ```typescript
      // src/routes/domain/health.ts
      import { Router } from 'express';
      import { HealthService } from '../../services/core/health-service';

      export const createHealthRoutes = (healthService: HealthService) => {
        const router = Router();
        
        router.get('/api/v1/domain/health', async (req, res) => {
          try {
            const status = await healthService.getSystemStatus();
            res.json(status);
          } catch (error) {
            res.status(500).json({ error: 'Failed to check system status' });
          }
        });
        
        router.get('/api/v1/domain/health/db', async (req, res) => {
          try {
            const dbStatus = await healthService.checkDbConnection();
            if (dbStatus) {
              res.json({ db_status: 'ok', record: dbStatus });
            } else {
              res.status(500).json({ db_status: 'error', message: 'Failed to retrieve database status' });
            }
          } catch (error) {
            res.status(500).json({ db_status: 'error', message: 'Database check failed' });
          }
        });
        
        return router;
      };
      ```

      **3. Domain Client Adapter Example:**
      ```typescript
      // src/clients/domain-client/health-client.ts
      import axios from 'axios';
      import { HealthService } from '../../services/core/health-service';
      import config from '../../config';

      export class HealthClient {
        private healthService?: HealthService;
        private baseUrl: string;
        private inProcessMode: boolean;
        
        constructor(options: { healthService?: HealthService }) {
          this.healthService = options.healthService;
          this.baseUrl = config.apiBaseUrl;
          this.inProcessMode = config.inProcessMode;
        }
        
        async getSystemStatus(): Promise<{ status: string; timestamp: string }> {
          if (this.inProcessMode && this.healthService) {
            // Direct service call when in same process
            return this.healthService.getSystemStatus();
          } else {
            // HTTP call when in separate process
            const response = await axios.get(`${this.baseUrl}/api/v1/domain/health`);
            return response.data;
          }
        }
        
        async checkDbConnection(): Promise<{ db_status: string; record?: any; message?: string }> {
          if (this.inProcessMode && this.healthService) {
            // Direct service call
            const result = await this.healthService.checkDbConnection();
            return result 
              ? { db_status: 'ok', record: result }
              : { db_status: 'error', message: 'Failed to retrieve database status' };
          } else {
            // HTTP call
            const response = await axios.get(`${this.baseUrl}/api/v1/domain/health/db`);
            return response.data;
          }
        }
      }
      ```

      **4. Edge Route Example:**
      ```typescript
      // src/routes/edge/health.ts
      import { Router } from 'express';
      import { HealthClient } from '../../clients/domain-client/health-client';

      export const createEdgeHealthRoutes = (healthClient: HealthClient) => {
        const router = Router();
        
        router.get('/api/v1/edge/health', async (req, res) => {
          try {
            const status = await healthClient.getSystemStatus();
            // Edge tier could transform the response if needed for the UI
            // In this simple case, we just pass it through
            res.json(status);
          } catch (error) {
            res.status(500).json({ error: 'Failed to check system status' });
          }
        });
        
        router.get('/api/v1/edge/health/db', async (req, res) => {
          try {
            const dbStatus = await healthClient.checkDbConnection();
            res.json(dbStatus);
          } catch (error) {
            res.status(500).json({ 
              db_status: 'error', 
              message: 'Failed to connect to database service'
            });
          }
        });
        
        return router;
      };
      ```
    </content>
  </code_examples>

  <product_summary_and_vision>
    <title>Product Summary and Vision</title>
    <content>
      The core idea is to develop "Liminal Type Chat" (working title), an open-source Generative AI chat application designed for the "Bring-Your-Own-Key" (BYOK) power user who wants maximum flexibility, extensibility, and control.

      The primary distribution model is a downloadable application that users can run locally with minimal setup, intended to serve individuals, families, or small, trusted teams. This means users will typically run a local API service and a local web service (for the UI) on their own machines. The vision is not to create a large-scale, multi-tenant SaaS application, but rather a flexible, user-centric tool optimized for small-scale deployments.

      Key characteristics include:

      - **Comprehensive BYOK Support**: Users leverage their own API keys for any LLM provider (OpenAI, Anthropic, Google, etc.), giving them complete control over cost, model choice, and privacy. No user data or keys are stored outside the local environment unless explicitly configured.

      - **Advanced LLM Orchestration**: Beyond simple chat, the application will support sophisticated LLM workflows including multi-LLM prompting (send one prompt to multiple models), LLM chaining (use one model's output as another's input), and support for Model Control Protocol (MCP) tooling.

      - **Extensibility Framework**: Pre and post-processing hooks for LLM interactions, a plugin architecture for adding new capabilities, and support for custom tools and function calling.

      - **Open Source & Local First**: Easily downloadable and runnable locally, promoting transparency and community contribution. SQLite provides robust local storage that's fast and reliable for typical usage patterns.

      - **Architectural Flexibility**: While optimized for local execution, the system maintains architectural points of indirection that allow for potential future adaptation to larger deployments or alternative databases. The local-run experience remains the priority.

      - **Simple Setup, Efficient Execution**: Minimal configuration required to get started, with performance optimized for small-scale usage. The application aims to provide a responsive, well-performing experience through lean implementation.

      - **Developer-Friendly**: Clean architecture, comprehensive documentation, and thorough testing make the codebase accessible for customization and extension.

      The application is designed for technical users who are comfortable managing API keys and running local server components, prioritizing power and flexibility over simplified UX for non-technical users.
    </content>
  </product_summary_and_vision>

  <mvp_scope>
    <title>Minimum Viable Product (MVP) Scope</title>
    <content>
      The MVP will focus on delivering a functional backend service and a very basic way to interact with it, proving the core BYOK chat loop.
      Primary Goal: A user can have a persistent conversation with an LLM using their own API key.

      Core Features:
      1.  **Context Thread Management (API-driven):**
          - Create new context threads.
          - Retrieve a specific context thread, including all its messages.
          - List available context threads (metadata only).
          - (Optional for MVP, but desirable) Update thread metadata (e.g., title).
          - (Optional for MVP, but desirable) Delete a context thread.
      2.  **Message Persistence (SQLite):**
          - All user and assistant messages within a context thread are stored in a local SQLite database.
          - The `context_threads` table will include a JSON field for the `messages` array.
      3.  **LLM Interaction (Single Model per Turn via API):**
          - An API endpoint to send a user's message (as part of a context thread) to a user-specified LLM.
          - The application proxies the request (using the user's key, provided via server-side config initially) and stores the LLM's response.
          - Track the `last_model` used and the model per assistant message.
      4.  **Basic User Association:**
          - A simple `users` table in SQLite.
          - Context threads are associated with a `user_id`. For MVP, this might be a single, implicit default user.
      5.  **Service API (RESTful):**
          - HTTP endpoints for all CRUD operations on context threads and for triggering LLM generation.

      Out of Scope for MVP:
      -   Sophisticated User Interface (UI will be minimal, possibly a CLI or simple test client).
      -   Advanced multi-model features (e.g., simultaneous prompting, complex chains).
      -   Real-time features beyond basic request-response (streaming from LLM is desirable but secondary to persistence).
      -   Complex authentication/authorization (focus on local use).
      -   User management beyond the basic `users` table.
      -   Public hosting or multi-tenancy.
      -   In-app management of LLM API keys (keys configured server-side).
    </content>
  </mvp_scope>

  <milestones>
    <title>Development Milestones</title>

    <milestone id="M0">
      <heading>Milestone 0: Project Initialization &amp; First Commit</heading>
      <content>
        - **Objective**: Set up the basic Node.js/TypeScript project structure, configuration files, initialize a Git repository, and perform the initial commit. This establishes the foundational codebase.
        - **Key Deliverables**:
          1.  **Directory Structure**: Create `src/` directory.
          2.  **Configuration Files**: 
              - `package.json` (basic project info, scripts: `dev`, `build`, `start`, `test`; initial dependencies: `express`, `dotenv`; dev dependencies: `typescript`, `@types/express`, `@types/node`, `ts-node`, `nodemon`, `jest`, `@types/jest`, `ts-jest`, `supertest`, `@types/supertest`).
              - `tsconfig.json` (appropriate compiler options).
              - `.gitignore` (common Node.js/TypeScript ignores like `node_modules/`, `dist/`, `.env`).
          3.  **Git Repository**: Initialize Git repository; first commit with all initial project files.
        - **Assumption**: Operating within the existing project root directory.
      </content>
    </milestone>

    <milestone id="M1">
      <heading>Milestone 1: Basic HTTP Server &amp; Domain Health Endpoint</heading>
      <content>
        - **Objective**: Stand up the Node.js/Express.js application with our architectural folder structure, implement the domain health check endpoint, and validate with tests.
        - **Key Deliverables**:
          1.  **Project Initialization**: 
              - Set up `package.json` for server (Node.js LTS, TypeScript, Express.js, Jest, Supertest)
              - Configure `tsconfig.json` for TypeScript compilation
              - Implement the core directory structure following our architectural pattern
          2.  **HTTP Server (Express.js)**:
              - Create main application entry point (`src/app.ts`, `src/server.ts`)
              - Set up modular routing structure with domain routes
              - Configure basic middleware (logging, error handling, etc.)
          3.  **Domain Health Service**:
              - Implement a simple health service in the domain tier
              - Create service method that returns health status and timestamp
          4.  **Domain Health Endpoint**:
              - Create `/api/v1/domain/health` route in domain routes
              - Return JSON response: `{ "status": "ok", "timestamp": "..." }`
          5.  **Testing**:
              - Unit tests for health service
              - Integration test for the domain health endpoint using Supertest
        - **Success Criteria**:
          - 90% test coverage for the health service
          - Passing integration test for the domain health endpoint
      </content>
    </milestone>

    <milestone id="M2">
      <heading>Milestone 2: SQLite Database Connectivity &amp; Domain DB Health Endpoint</heading>
      <content>
        - **Objective**: Set up SQLite database connectivity with a health check table, implement domain service methods for database health checks, and expose through a domain API endpoint.
        - **Key Deliverables**:
          1.  **Database Provider Setup**: 
              - Implement a database provider in the providers tier using `better-sqlite3`
              - Create configuration for connecting to SQLite
              - Set up proper dependency injection for the database provider
          2.  **Schema & Initialization**:
              - Create `schema.sql` with DDL for `health_check_table` (`id`, `status`, `checked_at`) 
              - Add DML for a seed record (`{ status: 'system_ready' }`)
              - Document manual initialization process for developers
          3.  **Domain Service Extension**:
              - Extend the health service with a `checkDbConnection()` method
              - Method should query the `health_check_table` and return status and timestamp
              - Implement proper error handling and connection validation
          4.  **Domain DB Health Endpoint**:
              - Create `/api/v1/domain/health/db` route in domain routes
              - Route should call the service method and return appropriate JSON response
              - Include proper error handling and status codes
          5.  **Testing**:
              - Unit tests for the database provider (with mocking)
              - Unit tests for the health service's database check method
              - Integration test for the domain DB health endpoint using Supertest
        - **Success Criteria**: 
          - 90% test coverage for the database provider and extended health service
          - Passing integration test for the domain DB health endpoint
          - Clean separation between the service logic and database implementation
      </content>
    </milestone>

    <milestone id="M3">
      <heading>Milestone 3: Edge-to-Domain Pattern Implementation for Health Checks</heading>
      <content>
        - **Objective**: Implement both edge and domain routes for our health checks, with the edge-to-domain adapter pattern, and validate with comprehensive integration tests.
        - **Key Deliverables**:
          1.  **Domain API Routes & Services**:
              - `/api/v1/domain/health` endpoint in the domain routes
              - `/api/v1/domain/health/db` endpoint in the domain routes
              - Core health service implementation that the domain routes call
          2.  **Edge-to-Domain Adapter**:
              - Domain client adapter with configurable mode (direct/HTTP)
              - Configuration toggle via environment variable
          3.  **Edge API Routes**:
              - `/api/v1/edge/health` in edge routes using the domain client
              - `/api/v1/edge/health/db` in edge routes using the domain client
          4.  **Comprehensive Testing**:
              - Unit tests for the domain client adapter (testing both modes)
              - Integration tests for domain routes (`/api/v1/domain/health` and `/api/v1/domain/health/db`)
              - Integration tests for edge routes (`/api/v1/edge/health` and `/api/v1/edge/health/db`)
              - End-to-end test that verifies the entire flow with the adapter in HTTP mode
        - **Success Criteria**:
          - 90% test coverage for the domain client adapter
          - All integration tests passing in both direct and HTTP modes
          - Configuration change (environment variable) successfully toggles adapter behavior without code changes
      </content>
    </milestone>

    <milestone id="M4">
      <heading>Milestone 4: React TypeScript Frontend with Health Check Features</heading>
      <content>
        - **Objective**: Create a modern React TypeScript frontend with build deployment to the Express server, comprehensive testing, and health check functionality.
        - **Key Deliverables**:
          1.  **React Application Setup**:
              - Initialize React app with TypeScript support
              - Configure appropriate linting and formatting
              - Create base application structure with routing
          2.  **Build & Deployment**:
              - Configure build process to output to a `build` directory
              - Create npm script to copy built assets to the server's `/public` folder
              - Add deployment documentation
          3.  **Testing Infrastructure**:
              - Set up Jest with React Testing Library
              - Configure test coverage reporting with 90% threshold
              - Add test helpers and utilities
          4.  **Health Check Interface**:
              - Create responsive UI with a clean, modern design
              - Implement health check page with two buttons:
                - Server health check button (calls `/api/v1/edge/health`)
                - Database health check button (calls `/api/v1/edge/health/db`)
              - Display results with appropriate visual feedback (success/error states)
              - Add loading states during API calls
          5.  **Component Tests**:
              - Unit tests for all components
              - Integration tests for health check API interactions
              - Mock API responses for predictable testing
        - **Success Criteria**:
          - 90% test coverage across the React codebase
          - Successful build and deployment to Express server's public directory
          - Health check buttons correctly call their respective endpoints and display results
          - Responsive design works on various screen sizes
      </content>
    </milestone>

  </milestones>

  <technology_stack_and_architecture>
    <title>Technology Stack &amp; Architecture (Initial Thoughts)</title>

    <application_tiers>
      <heading>Conceptual Application Tiers</heading>
      <content>
        The application is conceptually divided into the following tiers, allowing for clear separation of concerns and flexibility in how these tiers are mapped to processes in different deployment environments:

        1.  **UI Tier (Presentation Tier):**
            -   Responsibilities: User interaction, data presentation, capturing user input.
            -   Characteristics: The most user-proximate layer. Examples include web interfaces (React, Svelte, Vue, HTML/JS), command-line interfaces (CLI), desktop applications, or mobile applications.
            -   Interacts with: Edge/XPI/Router Tier.

        2.  **Edge/XPI/Router Tier (Experience/Adaptation Tier):**
            -   Responsibilities: Routing client requests, proxying to the Domain API Tier, transforming data structures between UI-friendly formats and canonical domain formats, and potentially aggregating calls to the Domain API Tier.
            -   Characteristics: Acts as a Backend-for-Frontend (BFF) or an API gateway. Can handle UI-specific concerns like session management or specialized caching.
            -   Interacts with: UI Tier and Domain API Tier.

        3.  **Domain API Tier (Core Services/Business Logic Tier):**
            -   Responsibilities: Defines and operates on the application's **canonical data formats** and **canonical core operations (use cases)**. Contains the primary business logic and domain models. Orchestrates interactions with various datasources and external services, translating their specific formats to/from the canonical model. Enforces business rules and data integrity around these canonical representations.
            -   Characteristics: UI-agnostic. Exposes its functionality through well-defined service interfaces or APIs that strictly adhere to these canonical data formats and operations. This tier is where provider/adapter patterns for integrations (like different database backends or LLM providers) are implemented to ensure consistency with the canonical model.
            -   Interacts with: Edge/XPI/Router Tier and Datasources &amp; External Services Tier.

        4.  **Datasources &amp; External Services Tier (Integration Tier):**
            -   Responsibilities: Provides access to persistent storage (databases like SQLite, PostgreSQL), messaging systems, external APIs (like LLMs), and other third-party services.
            -   Characteristics: Represents the actual external dependencies the application relies on.
            -   Interacts with: Domain API Tier.
      </content>
    </application_tiers>

    <process_layers_and_boundaries>
      <heading>Process Layers and Boundaries</heading>
      <content>
        A key architectural principle is to maintain a degree of decoupling between the conceptual Application Tiers and the physical process boundaries. This allows for flexibility in deployment across different environments (local, development, staging, production) and scales. While the Application Tiers define logical separation of concerns, the process model defines how these tiers are hosted and communicate.

        **Recommended Local Setup Process Model (MVP):**

        For the initial local-first development and execution, a simple and pragmatic process model is recommended:

        1.  **Main Application Process (Node.js Server):**
            -   Hosts the **Edge/XPI/Router Tier** logic (e.g., as Express.js routes or similar HTTP request handlers).
            -   Hosts the **Domain API Tier** logic (e.g., service classes/modules called by the route handlers).
            -   This single Node.js process, therefore, encapsulates the responsibilities of Application Tiers 2 and 3.
            -   It directly interacts with the **Datasources &amp; External Services Tier** (e.g., local SQLite database file, external LLM APIs via HTTP).

        2.  **UI Client Process:**
            -   The **UI Tier** will run in its own process, separate from the main application process.
            -   If a web-based UI (even a simple HTML/JS test page), the browser itself constitutes this process. The Node.js server might serve the static UI files, but the UI code executes in the browser.
            -   If a Command Line Interface (CLI) is used, each invocation of the CLI tool is a separate process.
            -   If API testing tools (like Postman/Insomnia) are used, they run as their own distinct processes.

        This local setup prioritizes ease of development and a minimal number of moving parts, while still respecting the conceptual separation of the Application Tiers within the codebase of the Node.js server.
      </content>
    </process_layers_and_boundaries>

  </technology_stack_and_architecture>

  <security>
    <title>Access Security</title>
    <content>
      - MVP: Geared towards local/trusted network use. Security via network controls or a simple shared secret if the API is exposed.
      - Future: OAuth 2.0 / OpenID Connect if broader access is needed (TBD).
    </content>
  </security>

  <project_setup>
    <title>Project Setup</title>
    <content>
      This section outlines the minimal setup for the project.

      - **Runtime Environment**: 
        - Node.js LTS (Long-Term Support) version, currently Node.js 20.x
        - Express.js for HTTP server, API routes, and serving static content
      - **Package Manager**: npm
      - **Version Control**: Git
      - **Open Source License**: MIT License
      - **Project Status**: Early development, not yet stable enough for external contributions

      - **Application Structure**:
        - Single Express.js application that serves both the API and static UI files
        - Clear internal separation between Edge/XPI, Domain, and UI tiers
        - Frontend code (React or similar) built and deployed to Express public directory

      - **Directory Structure**:
        - `/server`: Backend Node.js/Express application
          - `/src`: Server source code
            - `/routes`: API routes
              - `/edge`: Edge/XPI tier routes (UI-optimized endpoints - `/api/v1/edge/...`)
              - `/domain`: Domain API routes (canonical formats - `/api/v1/domain/...`) 
            - `/services`: Business logic (Domain tier)
              - `/core`: Core domain services
              - `/adapters`: Adapters for external integrations (DB, LLMs)
            - `/models`: Data models and interfaces
              - `/domain`: Canonical domain models
              - `/dto`: Data Transfer Objects (UI/external formats)
              - `/transforms`: Transform functions between domain and DTO models
            - `/clients`: Client libraries
              - `/domain-client`: Adapter for edge-to-domain communication (configurable for in-process or HTTP)
            - `/providers`: Integration adapters 
              - `/db`: Database access 
              - `/storage`: Document storage (local/cloud) 
              - `/llm`: Language model providers
            - `/config`: Configuration management
            - `/middleware`: Express middleware
            - `/utils`: Utility functions
          - `/public`: Static frontend files (served by Express)
          - `/dist`: Compiled JavaScript
          - `/db`: Database files and migrations
          - `/data`: Document/file storage

          **NOTE**: The Edge-to-Domain communication pattern uses a configurable adapter approach. When running in a single process, the Edge routes can call Domain services directly via the domain-client adapter for efficiency. When distributed across processes, the same adapter seamlessly switches to making HTTP calls to the Domain API endpoints. This provides flexibility in deployment while optimizing for the local-first case.

        - `/client`: Frontend application
          - `/src`: Frontend source code
          - `/public`: Static assets
          - `/build`: Build output (copied to `/server/public` during deployment)

      - **Configuration Files**:
        - `package.json`: Project metadata, dependencies, and scripts (one each for server and client)
        - `tsconfig.json`: TypeScript compiler options
        - `.env`: Environment variables (not checked into version control)
        - `.gitignore`: Files/directories to ignore in version control
        
      - **Future Scaling Considerations**:
        - **Database**: Design with adapter pattern to allow transition from SQLite to PostgreSQL if needed
        - **Document Storage**: Implement abstraction that works with local files or cloud storage (S3, etc.)
        - **Process Distribution**: Maintain clean separation of tiers to allow future distribution
        - **Multi-tenancy**: Consider data isolation patterns if moving beyond personal/family use
    </content>
  </project_setup>

  <development_standards>
    <title>Development Standards</title>
    
    <naming_conventions>
      <heading>Naming Conventions</heading>
      <content>
        - **Database**: Use `snake_case` for all table and column names
          - Examples: `context_threads`, `user_id`, `last_model`

        - **JavaScript/TypeScript Variables**: Use `camelCase` for variables and object properties
          - Examples: `userId`, `contextThread`, `lastModel`

        - **Classes/Types/Interfaces**: Use `PascalCase` for classes, types, and interfaces
          - Examples: `ContextThread`, `UserRepository`, `GenerateResponse`

        - **Files/Resources**: Use `kebab-case` for file names and URL resources
          - Examples: `context-thread.ts`, `user-repository.ts`, `/api/context-threads`

        - **Constants**: Use `UPPER_SNAKE_CASE` for constants
          - Examples: `MAX_TOKEN_COUNT`, `DEFAULT_MODEL`
      </content>
    </naming_conventions>
    
    <code_formatting>
      <heading>Code Formatting and Style</heading>
      <content>
        - **Linting & Formatting**:
          - ESLint with TypeScript plugin for code quality
          - Prettier for consistent formatting
          - Configuration in `.eslintrc.js` and `.prettierrc`

        - **Line Length**: Maximum 100 characters per line

        - **Indentation**: 2 spaces (not tabs)

        - **Quotes**: Single quotes for strings, backticks for template literals

        - **Semicolons**: Required at the end of statements

        - **Import Order**:
          1. External libraries
          2. Internal modules (absolute paths)
          3. Local files (relative paths)
          4. Type imports
          Each group separated by a blank line

        - **Trailing Commas**: Required for multi-line arrays and objects

        - **Interface vs Type**: Prefer interfaces for object definitions, types for unions/intersections
      </content>
    </code_formatting>

    <documentation_standards>
      <heading>Documentation Standards</heading>
      <content>
        - **JSDoc Comments**:
          - Required for all public functions, classes, and interfaces
          - Include @param, @returns, and @throws tags as appropriate
          - Example:
          ```typescript
          /**
           * Retrieves a context thread by its ID
           * @param threadId - The UUID of the thread to retrieve
           * @returns The context thread if found
           * @throws NotFoundException if thread doesn't exist
           */
          async getThreadById(threadId: string): Promise<ContextThread>
          ```

        - **README Files**:
          - Each significant directory should have a README.md explaining its purpose
          - Main README.md should include setup instructions, project overview, and development guidelines

        - **Code Comments**:
          - Focus on WHY not WHAT (code should be self-explanatory)
          - Comment complex algorithms, business rules, or non-obvious decisions
          - Use TODO: comments for incomplete work (but track these in issues too)

        - **API Documentation**:
          - All API endpoints must include documentation comments
          - Document request/response formats, possible status codes
          - Use OpenAPI/Swagger annotations where appropriate
      </content>
    </documentation_standards>

    <testing_standards>
      <heading>Testing Standards</heading>
      <content>
        - **Coverage Requirements**:
          - Domain services: 90% minimum coverage
          - Edge/route handlers: 80% minimum coverage
          - Utility functions: 80% minimum coverage

        - **Test Structure**:
          - Use Jest's describe/it pattern for organization
          - Group tests by functionality, not implementation details
          - Follow AAA pattern (Arrange, Act, Assert)

        - **Test Naming**:
          - Format: `should [expected behavior] when [condition]`
          - Examples: `should return 404 when thread not found`

        - **Test Types**:
          - Unit tests: Test individual functions in isolation
          - Integration tests: Test interactions between components
          - HTTP tests: Test API endpoints using Supertest

        - **Mocking**:
          - Mock external dependencies (DB, LLM providers, etc.) in unit tests
          - Use Jest mocks and spies consistently
          - For integration tests, prefer test doubles over network calls

        - **Test Data**:
          - Use factories or fixtures for test data generation
          - Avoid hardcoding test data directly in test files
          - Explain edge cases with comments
      </content>
    </testing_standards>

    <error_handling>
      <heading>Error Handling Standards</heading>
      <content>
        - **Error Types**:
          - Define domain-specific error classes extending Error
          - Include error code, message, and contextual data
          - Example categories: ValidationError, NotFoundError, ServiceError

        - **Error Propagation**:
          - Domain services should throw typed errors
          - Edge layer translates errors to appropriate HTTP responses
          - Always preserve stack traces (`new Error('message', { cause: originalError })`)

        - **Async Error Handling**:
          - Use try/catch with async/await
          - Avoid unhandled promise rejections

        - **Client Error Messages**:
          - User-friendly messages for client-facing errors
          - Never expose sensitive information in error messages
          - Include request IDs for traceability

        - **Logging**:
          - Log all errors with appropriate context
          - Debug-level logging for handled errors
          - Error-level logging for unexpected errors
      </content>
    </error_handling>

    <async_code_standards>
      <heading>Async Code Standards</heading>
      <content>
        - **Prefer async/await** over direct Promise chains for readability

        - **Promise Management**:
          - Use `Promise.all()` for parallel operations
          - Use `Promise.allSettled()` when partial failures are acceptable

        - **Timeouts**:
          - Add timeouts to external service calls
          - Implement with Promise race or AbortController

        - **Error Propagation**:
          - Always catch async errors at boundary layers
          - Include original error as `cause` when re-throwing

        - **Testing**:
          - Use Jest's `done()` or `async/await` consistently
          - Test both success and failure paths

        - **Avoid**:
          - Mixing callback and Promise patterns
          - Deeply nested async operations
          - Unhandled Promise rejections
      </content>
    </async_code_standards>

    <dependency_injection>
      <heading>Dependency Injection Standards</heading>
      <content>
        - **Constructor Injection**:
          - Pass dependencies through constructor parameters
          - Example: `constructor(private dbProvider: DatabaseProvider, private configService: ConfigService) {}`

        - **Dependencies as Interfaces**:
          - Define interfaces for all dependencies
          - Example: `interface DatabaseProvider { query(sql: string, params?: any[]): Promise<any> }`

        - **Factories**:
          - Use factory functions to create instances with dependencies
          - Example: `const createHealthService = (dbProvider) => new HealthService(dbProvider);`

        - **Testing**:
          - Pass mock implementations to constructors in tests
          - Example: `const healthService = new HealthService(mockDbProvider);`

        - **Avoid**:
          - Singletons (except in specific justified cases)
          - Direct imports of concrete implementations inside classes
          - Service locator patterns
      </content>
    </dependency_injection>
    
    <database_structure>
      <heading>Database Structure</heading>
      <content>
        - Tables should have singular names for entity tables (e.g., `user`) and plural names for junction tables (e.g., `context_threads`)
        - Each table should have a primary key, typically `id` as UUID
        - Use `created_at` and `updated_at` timestamps for auditing
        - Foreign keys should follow the pattern `<table_name>_id`
      </content>
    </database_structure>
  </development_standards>

  <automated_testing>
    <title>Automated Testing Strategy</title>
    <content>
      - Layers: Unit tests (Jest/Vitest), Integration tests (for API endpoints and service-to-DB interactions).
      - Tooling: TBD, align with chosen framework. Supertest for API integration tests.
      - E2E: Future consideration if a significant UI is developed.
    </content>
  </automated_testing>

  <local_development_setup>
    <title>Local Development Setup</title>
    <content>
      - Database: Local SQLite file.
      - Environment: Node.js, TypeScript. `.env` files for configuration.
      - Scripts: Standard `dev`, `build`, `start`, `test`, `lint`, `db:migrate` (simple SQL scripts).
    </content>
  </local_development_setup>

  <deployment>
    <title>Deployment Tooling &amp; Implementation Service</title>
    <content>
      - MVP: Primarily local execution. No complex deployment tooling.
      - Future if hosted: Docker, PaaS (Vercel, Railway, Fly.io), CI/CD (GitHub Actions) - TBD.
    </content>
  </deployment>

  <development_approach>
    <title>Development Approach</title>
    <content>
      Liminal Type Chat will be developed in incremental milestones, each delivering a thin slice of complete functionality from database to UI:

      - **MVP 1**: Focus on core infrastructure, health endpoints, and basic architecture patterns
      - **MVP 2**: Once MVP 1 is complete, new milestones will be defined for conversation functionality
      - **Future MVPs**: Will add advanced features like multi-LLM orchestration, plugins, etc.

      Each milestone follows these principles:
      - Delivers end-to-end functionality (from database to UI)
      - Includes comprehensive tests
      - Establishes patterns that will scale to future features
      - Results in a deployable, working system (even if limited in scope)

      This approach allows for early validation of architectural decisions and creates a foundation for progressive enhancement.
    </content>
  </development_approach>

  <cascade_configuration>
    <title>Windsurf Cascade Configuration</title>
    <content>
      To ensure consistent development with Cascade, we'll use project-level configuration to include this project plan in all prompts. This setup provides Cascade with full context about the project architecture, standards, and milestones.

      **Configuration Steps:**
      1. Create a `.cascade` directory at the project root
      2. Add a `project-prompt.md` file containing:
         ```markdown
         # Liminal Type Chat Project Context
         
         This is a project-level prompt for the Liminal Type Chat application.
         
         The complete architecture and development standards are documented in `project-plan.xml`.
         Please read this file thoroughly before making any code changes.
         
         Key points to remember:
         - Follow the tiered architecture (Domain, Edge/XPI, UI) with clean separation
         - Implement the domain client adapter pattern for tier communication
         - Adhere to all naming conventions and coding standards
         - Maintain test coverage requirements
         - Commit after each significant batch of changes
         ```
      3. Make sure project-plan.xml is properly tracked and accessible

      This configuration ensures that Cascade always has access to the project context and development standards.
    </content>
  </cascade_configuration>

  <ai_coding_guidelines>
    <title>AI-Assisted Coding Guidelines</title>
    <content>
      When using Cascade in turbo mode for this project, follow these guidelines:

      1. **Regular Commits**:
         - After each logical batch of file changes, commit with a descriptive message
         - Example: `git add . && git commit -m "Implement domain health service with unit tests"`
         - Keep commits focused on a single logical change

      2. **Prompt Structure**:
         - Begin with clear statement of what you're trying to accomplish
         - Reference specific milestones from the project plan
         - Provide context about where you are in the implementation

      3. **Code Review**:
         - Periodically ask Cascade to review recently implemented code
         - Check for adherence to development standards
         - Verify test coverage meets requirements

      4. **Implementation Order**:
         - Start with domain models and interfaces
         - Implement services with unit tests
         - Add routes with integration tests
         - Finally build UI components

      5. **Documentation**:
         - Request inline documentation following standards
         - Ask for README updates after significant milestones
         - Ensure generated code includes appropriate JSDoc comments

      Following these guidelines will maximize the effectiveness of AI-assisted development while maintaining code quality and project structure integrity.
    </content>
  </ai_coding_guidelines>
</project_plan>
